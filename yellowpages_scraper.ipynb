{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f674c2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31 listings.\n",
      "Skipping listing due to parse error: 'NoneType' object has no attribute 'text'\n",
      "Saved to yellow_pages_general_contractors.xlsx\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.worksheet.datavalidation import DataValidation\n",
    "\n",
    "def parse_listing(listing, source_url):\n",
    "    try:\n",
    "        company = listing.select_one(\".business-name span\").text.strip()\n",
    "        phone = listing.select_one(\".phones\").text.strip() if listing.select_one(\".phones\") else \"\"\n",
    "        address_street = listing.select_one(\".street-address\")\n",
    "        address_locality = listing.select_one(\".locality\")\n",
    "        full_address = \" \".join(filter(None, [\n",
    "            address_street.text.strip() if address_street else \"\",\n",
    "            address_locality.text.strip() if address_locality else \"\"\n",
    "        ]))\n",
    "        website = listing.select_one(\".track-visit-website\")[\"href\"] if listing.select_one(\".track-visit-website\") else \"N/A\"\n",
    "        detail_link = \"https://www.yellowpages.com\" + listing.select_one(\".business-name\")[\"href\"]\n",
    "\n",
    "        return {\n",
    "            \"Company Name\": company,\n",
    "            \"Industry\": \"Construction\",\n",
    "            \"Contact Name\": \"\",\n",
    "            \"Email Address\": \"\",\n",
    "            \"Phone Number\": phone,\n",
    "            \"Website URL\": website,\n",
    "            \"Address\": full_address,\n",
    "            \"Date Added\": datetime.now().strftime(\"%-m/%-d/%y\"),\n",
    "            \"Date Contacted\": \"\",\n",
    "            \"Notes\": detail_link,\n",
    "            \"Source\": source_url,\n",
    "            \"Called\": \"\",\n",
    "            \"Followed Up\": \"\",\n",
    "            \"Closed\": \"\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(\"Skipping listing due to parse error:\", e)\n",
    "        return None\n",
    "\n",
    "def add_checkboxes(filepath):\n",
    "    wb = load_workbook(filepath)\n",
    "    ws = wb.active\n",
    "    \n",
    "    checkbox_validation = DataValidation(type=\"list\", formula1='\"☐,☑\"', allow_blank=True)\n",
    "    ws.add_data_validation(checkbox_validation)\n",
    "    \n",
    "    # Find checkbox columns (Called, Followed Up, Closed)\n",
    "    headers = {cell.value: cell.column for cell in ws[1]}\n",
    "    checkbox_cols = [\"Called\", \"Followed Up\", \"Closed\"]\n",
    "    \n",
    "    for col_name in checkbox_cols:\n",
    "        if col_name in headers:\n",
    "            col_idx = headers[col_name]\n",
    "            col_letter = ws.cell(row=1, column=col_idx).column_letter\n",
    "            for row in range(2, ws.max_row + 1):\n",
    "                cell = ws.cell(row=row, column=col_idx)\n",
    "                cell.value = \"☐\"\n",
    "                checkbox_validation.add(cell)\n",
    "    \n",
    "    wb.save(filepath)\n",
    "\n",
    "def scrape_yellowpages_rendered(url):\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n",
    "\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    driver.get(url)\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(2)\n",
    "\n",
    "    try:\n",
    "        WebDriverWait(driver, 15).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"result\"))\n",
    "        )\n",
    "    except:\n",
    "        print(\"Timeout waiting for listings to load.\")\n",
    "        print(driver.page_source[:1000])\n",
    "        driver.quit()\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    listings = driver.find_elements(By.CLASS_NAME, \"result\")\n",
    "    print(f\"Found {len(listings)} listings.\")\n",
    "\n",
    "    data = []\n",
    "    for listing in listings:\n",
    "        soup = BeautifulSoup(listing.get_attribute(\"outerHTML\"), \"html.parser\")\n",
    "        parsed = parse_listing(soup, url)\n",
    "        if parsed:\n",
    "            data.append(parsed)\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    output_file = \"yellow_pages_general_contractors.xlsx\"\n",
    "    df.to_excel(output_file, index=False)\n",
    "    \n",
    "    # Add checkbox validation\n",
    "    add_checkboxes(output_file)\n",
    "    \n",
    "    print(f\"Saved to {output_file}\")\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = \"https://www.yellowpages.com/brooklyn-ny/general-contractors\"\n",
    "    scrape_yellowpages_rendered(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d58881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "➡️ Scraping Page 1: https://www.yellowpages.com/brooklyn-ny/general-contractors\n",
      "⚠️ Timeout on page 1 — printing debug HTML:\n",
      "<html class=\"no-js\" lang=\"en-US\"><!--<![endif]--><head>\n",
      "<title>Attention Required! | Cloudflare</title>\n",
      "<meta charset=\"UTF-8\">\n",
      "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\n",
      "<meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\">\n",
      "<meta name=\"robots\" content=\"noindex, nofollow\">\n",
      "<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\">\n",
      "<link rel=\"stylesheet\" id=\"cf_styles-css\" href=\"/cdn-cgi/styles/cf.errors.css\">\n",
      "<!--[if lt IE 9]><link rel=\"stylesheet\" id='cf_styles-ie-css' href=\"/cdn-cgi/styles/cf.errors.ie.css\" /><![endif]-->\n",
      "<style>body{margin:0;padding:0}</style>\n",
      "\n",
      "\n",
      "<!--[if gte IE 10]><!-->\n",
      "<script>\n",
      "  if (!navigator.cookieEnabled) {\n",
      "    window.addEventListener('DOMContentLoaded', function () {\n",
      "      var cookieEl = document.getElementById('cookie-alert');\n",
      "      cookieEl.style.display = 'block';\n",
      "    })\n",
      "  }\n",
      "</script>\n",
      "<!--<![endif]-->\n",
      "\n",
      "\n",
      "</head>\n",
      "<body>\n",
      "  <div id=\"cf-wrapper\">\n",
      "    <div class=\"cf-alert cf-alert-error cf-cookie-error\" id=\"cookie-alert\" data-tran\n",
      "\n",
      "➡️ Scraping Page 2: https://www.yellowpages.com/brooklyn-ny/general-contractors?page=2\n",
      "⚠️ Timeout on page 2 — printing debug HTML:\n",
      "<html class=\"no-js\" lang=\"en-US\"><!--<![endif]--><head>\n",
      "<title>Attention Required! | Cloudflare</title>\n",
      "<meta charset=\"UTF-8\">\n",
      "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\n",
      "<meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\">\n",
      "<meta name=\"robots\" content=\"noindex, nofollow\">\n",
      "<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\">\n",
      "<link rel=\"stylesheet\" id=\"cf_styles-css\" href=\"/cdn-cgi/styles/cf.errors.css\">\n",
      "<!--[if lt IE 9]><link rel=\"stylesheet\" id='cf_styles-ie-css' href=\"/cdn-cgi/styles/cf.errors.ie.css\" /><![endif]-->\n",
      "<style>body{margin:0;padding:0}</style>\n",
      "\n",
      "\n",
      "<!--[if gte IE 10]><!-->\n",
      "<script>\n",
      "  if (!navigator.cookieEnabled) {\n",
      "    window.addEventListener('DOMContentLoaded', function () {\n",
      "      var cookieEl = document.getElementById('cookie-alert');\n",
      "      cookieEl.style.display = 'block';\n",
      "    })\n",
      "  }\n",
      "</script>\n",
      "<!--<![endif]-->\n",
      "\n",
      "\n",
      "</head>\n",
      "<body>\n",
      "  <div id=\"cf-wrapper\">\n",
      "    <div class=\"cf-alert cf-alert-error cf-cookie-error\" id=\"cookie-alert\" data-tran\n",
      "\n",
      "➡️ Scraping Page 3: https://www.yellowpages.com/brooklyn-ny/general-contractors?page=3\n",
      "⚠️ Timeout on page 3 — printing debug HTML:\n"
     ]
    },
    {
     "ename": "MaxRetryError",
     "evalue": "HTTPConnectionPool(host='localhost', port=52756): Max retries exceeded with url: /session/484f018fad2b817cd17b73761fae174d/source (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10fc26ad0>: Failed to establish a new connection: [Errno 61] Connection refused'))",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 71\u001b[39m, in \u001b[36mscrape_yellowpages_rendered\u001b[39m\u001b[34m(base_url, max_pages)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[43mWebDriverWait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43muntil\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m        \u001b[49m\u001b[43mEC\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpresence_of_element_located\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCLASS_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresult\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.projects/scripts/yp/yp-scraper-env/lib/python3.13/site-packages/selenium/webdriver/support/wait.py:145\u001b[39m, in \u001b[36mWebDriverWait.until\u001b[39m\u001b[34m(self, method, message)\u001b[39m\n\u001b[32m    144\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m TimeoutException(message, screen, stacktrace)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mConnectionRefusedError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.projects/scripts/yp/yp-scraper-env/lib/python3.13/site-packages/urllib3/connection.py:198\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     sock = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m socket.gaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.projects/scripts/yp/yp-scraper-env/lib/python3.13/site-packages/urllib3/util/connection.py:85\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, socket_options)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     87\u001b[39m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.projects/scripts/yp/yp-scraper-env/lib/python3.13/site-packages/urllib3/util/connection.py:73\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, socket_options)\u001b[39m\n\u001b[32m     72\u001b[39m     sock.bind(source_address)\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[43msock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[31mConnectionRefusedError\u001b[39m: [Errno 61] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mNewConnectionError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.projects/scripts/yp/yp-scraper-env/lib/python3.13/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.projects/scripts/yp/yp-scraper-env/lib/python3.13/site-packages/urllib3/connectionpool.py:493\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    492\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[32m    505\u001b[39m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[32m    506\u001b[39m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.projects/scripts/yp/yp-scraper-env/lib/python3.13/site-packages/urllib3/connection.py:445\u001b[39m, in \u001b[36mHTTPConnection.request\u001b[39m\u001b[34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    444\u001b[39m     \u001b[38;5;28mself\u001b[39m.putheader(header, value)\n\u001b[32m--> \u001b[39m\u001b[32m445\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[38;5;66;03m# If we're given a body we start sending that in chunks.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:1331\u001b[39m, in \u001b[36mHTTPConnection.endheaders\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1330\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[32m-> \u001b[39m\u001b[32m1331\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:1091\u001b[39m, in \u001b[36mHTTPConnection._send_output\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1090\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m._buffer[:]\n\u001b[32m-> \u001b[39m\u001b[32m1091\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1093\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1094\u001b[39m \n\u001b[32m   1095\u001b[39m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:1035\u001b[39m, in \u001b[36mHTTPConnection.send\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m   1034\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_open:\n\u001b[32m-> \u001b[39m\u001b[32m1035\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1036\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.projects/scripts/yp/yp-scraper-env/lib/python3.13/site-packages/urllib3/connection.py:276\u001b[39m, in \u001b[36mHTTPConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    275\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m     \u001b[38;5;28mself\u001b[39m.sock = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    277\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tunnel_host:\n\u001b[32m    278\u001b[39m         \u001b[38;5;66;03m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.projects/scripts/yp/yp-scraper-env/lib/python3.13/site-packages/urllib3/connection.py:213\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[32m    214\u001b[39m         \u001b[38;5;28mself\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    215\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    217\u001b[39m sys.audit(\u001b[33m\"\u001b[39m\u001b[33mhttp.client.connect\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m.host, \u001b[38;5;28mself\u001b[39m.port)\n",
      "\u001b[31mNewConnectionError\u001b[39m: <urllib3.connection.HTTPConnection object at 0x10fc26ad0>: Failed to establish a new connection: [Errno 61] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mMaxRetryError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 112\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;66;03m# Run\u001b[39;00m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m     \u001b[43mscrape_yellowpages_rendered\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBASE_URL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMAX_PAGES\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 76\u001b[39m, in \u001b[36mscrape_yellowpages_rendered\u001b[39m\u001b[34m(base_url, max_pages)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     75\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m⚠️ Timeout on page \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m — printing debug HTML:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mdriver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpage_source\u001b[49m[:\u001b[32m1000\u001b[39m])\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     79\u001b[39m driver.execute_script(\u001b[33m\"\u001b[39m\u001b[33mwindow.scrollTo(0, document.body.scrollHeight);\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.projects/scripts/yp/yp-scraper-env/lib/python3.13/site-packages/undetected_chromedriver/__init__.py:806\u001b[39m, in \u001b[36mChrome.__getattribute__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m    804\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, item):\n\u001b[32m    805\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mdebug\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m806\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    807\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    808\u001b[39m         \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01minspect\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.projects/scripts/yp/yp-scraper-env/lib/python3.13/site-packages/selenium/webdriver/remote/webdriver.py:570\u001b[39m, in \u001b[36mWebDriver.page_source\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    562\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m    563\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpage_source\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m    564\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Gets the source of the current page.\u001b[39;00m\n\u001b[32m    565\u001b[39m \n\u001b[32m    566\u001b[39m \u001b[33;03m    Example:\u001b[39;00m\n\u001b[32m    567\u001b[39m \u001b[33;03m    --------\u001b[39;00m\n\u001b[32m    568\u001b[39m \u001b[33;03m    >>> print(driver.page_source)\u001b[39;00m\n\u001b[32m    569\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m570\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[43m.\u001b[49m\u001b[43mGET_PAGE_SOURCE\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.projects/scripts/yp/yp-scraper-env/lib/python3.13/site-packages/selenium/webdriver/remote/webdriver.py:427\u001b[39m, in \u001b[36mWebDriver.execute\u001b[39m\u001b[34m(self, driver_command, params)\u001b[39m\n\u001b[32m    424\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33msessionId\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[32m    425\u001b[39m         params[\u001b[33m\"\u001b[39m\u001b[33msessionId\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.session_id\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcommand_executor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[32m    429\u001b[39m     \u001b[38;5;28mself\u001b[39m.error_handler.check_response(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.projects/scripts/yp/yp-scraper-env/lib/python3.13/site-packages/selenium/webdriver/remote/remote_connection.py:404\u001b[39m, in \u001b[36mRemoteConnection.execute\u001b[39m\u001b[34m(self, command, params)\u001b[39m\n\u001b[32m    402\u001b[39m trimmed = \u001b[38;5;28mself\u001b[39m._trim_large_entries(params)\n\u001b[32m    403\u001b[39m LOGGER.debug(\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, command_info[\u001b[32m0\u001b[39m], url, \u001b[38;5;28mstr\u001b[39m(trimmed))\n\u001b[32m--> \u001b[39m\u001b[32m404\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand_info\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.projects/scripts/yp/yp-scraper-env/lib/python3.13/site-packages/selenium/webdriver/remote/remote_connection.py:428\u001b[39m, in \u001b[36mRemoteConnection._request\u001b[39m\u001b[34m(self, method, url, body)\u001b[39m\n\u001b[32m    425\u001b[39m     body = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    427\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client_config.keep_alive:\n\u001b[32m--> \u001b[39m\u001b[32m428\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    429\u001b[39m     statuscode = response.status\n\u001b[32m    430\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.projects/scripts/yp/yp-scraper-env/lib/python3.13/site-packages/urllib3/_request_methods.py:135\u001b[39m, in \u001b[36mRequestMethods.request\u001b[39m\u001b[34m(self, method, url, body, fields, headers, json, **urlopen_kw)\u001b[39m\n\u001b[32m    132\u001b[39m     urlopen_kw[\u001b[33m\"\u001b[39m\u001b[33mbody\u001b[39m\u001b[33m\"\u001b[39m] = body\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._encode_url_methods:\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest_encode_url\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfields\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m    139\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43murlopen_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request_encode_body(\n\u001b[32m    144\u001b[39m         method, url, fields=fields, headers=headers, **urlopen_kw\n\u001b[32m    145\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.projects/scripts/yp/yp-scraper-env/lib/python3.13/site-packages/urllib3/_request_methods.py:182\u001b[39m, in \u001b[36mRequestMethods.request_encode_url\u001b[39m\u001b[34m(self, method, url, fields, headers, **urlopen_kw)\u001b[39m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fields:\n\u001b[32m    180\u001b[39m     url += \u001b[33m\"\u001b[39m\u001b[33m?\u001b[39m\u001b[33m\"\u001b[39m + urlencode(fields)\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mextra_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.projects/scripts/yp/yp-scraper-env/lib/python3.13/site-packages/urllib3/poolmanager.py:443\u001b[39m, in \u001b[36mPoolManager.urlopen\u001b[39m\u001b[34m(self, method, url, redirect, **kw)\u001b[39m\n\u001b[32m    441\u001b[39m     response = conn.urlopen(method, url, **kw)\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m443\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    445\u001b[39m redirect_location = redirect \u001b[38;5;129;01mand\u001b[39;00m response.get_redirect_location()\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.projects/scripts/yp/yp-scraper-env/lib/python3.13/site-packages/urllib3/connectionpool.py:871\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    866\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[32m    867\u001b[39m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[32m    868\u001b[39m     log.warning(\n\u001b[32m    869\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m) after connection broken by \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, retries, err, url\n\u001b[32m    870\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m871\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[32m    890\u001b[39m redirect_location = redirect \u001b[38;5;129;01mand\u001b[39;00m response.get_redirect_location()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.projects/scripts/yp/yp-scraper-env/lib/python3.13/site-packages/urllib3/connectionpool.py:871\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    866\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[32m    867\u001b[39m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[32m    868\u001b[39m     log.warning(\n\u001b[32m    869\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m) after connection broken by \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, retries, err, url\n\u001b[32m    870\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m871\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[32m    890\u001b[39m redirect_location = redirect \u001b[38;5;129;01mand\u001b[39;00m response.get_redirect_location()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.projects/scripts/yp/yp-scraper-env/lib/python3.13/site-packages/urllib3/connectionpool.py:871\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    866\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[32m    867\u001b[39m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[32m    868\u001b[39m     log.warning(\n\u001b[32m    869\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m) after connection broken by \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, retries, err, url\n\u001b[32m    870\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m871\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[32m    890\u001b[39m redirect_location = redirect \u001b[38;5;129;01mand\u001b[39;00m response.get_redirect_location()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.projects/scripts/yp/yp-scraper-env/lib/python3.13/site-packages/urllib3/connectionpool.py:841\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    838\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(new_e, (\u001b[38;5;167;01mOSError\u001b[39;00m, HTTPException)):\n\u001b[32m    839\u001b[39m     new_e = ProtocolError(\u001b[33m\"\u001b[39m\u001b[33mConnection aborted.\u001b[39m\u001b[33m\"\u001b[39m, new_e)\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m retries = \u001b[43mretries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m=\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    844\u001b[39m retries.sleep()\n\u001b[32m    846\u001b[39m \u001b[38;5;66;03m# Keep track of the error for the retry warning.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.projects/scripts/yp/yp-scraper-env/lib/python3.13/site-packages/urllib3/util/retry.py:519\u001b[39m, in \u001b[36mRetry.increment\u001b[39m\u001b[34m(self, method, url, response, error, _pool, _stacktrace)\u001b[39m\n\u001b[32m    517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m new_retry.is_exhausted():\n\u001b[32m    518\u001b[39m     reason = error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[32m--> \u001b[39m\u001b[32m519\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    521\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[33mIncremented Retry for (url=\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m, url, new_retry)\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m new_retry\n",
      "\u001b[31mMaxRetryError\u001b[39m: HTTPConnectionPool(host='localhost', port=52756): Max retries exceeded with url: /session/484f018fad2b817cd17b73761fae174d/source (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x10fc26ad0>: Failed to establish a new connection: [Errno 61] Connection refused'))"
     ]
    }
   ],
   "source": [
    "# # ---------------- SETTINGS ----------------\n",
    "# MAX_PAGES = 10\n",
    "# BASE_URL = \"https://www.yellowpages.com/brooklyn-ny/general-contractors\"\n",
    "# OUTPUT_FILE = \"yellow_pages_general_contractors.xlsx\"\n",
    "# HEADLESS = True\n",
    "# USER_AGENT = (\n",
    "#     \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) \"\n",
    "#     \"AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "# )\n",
    "\n",
    "# # ---------------- SCRAPER ----------------\n",
    "# import undetected_chromedriver as uc\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "# from bs4 import BeautifulSoup\n",
    "# import pandas as pd\n",
    "# from datetime import datetime\n",
    "# import time\n",
    "# import random\n",
    "\n",
    "# def parse_listing(listing, page_number=None):\n",
    "#     try:\n",
    "#         company = listing.select_one(\".business-name span\").text.strip()\n",
    "#         phone = listing.select_one(\".phones\").text.strip() if listing.select_one(\".phones\") else \"\"\n",
    "#         address_street = listing.select_one(\".street-address\")\n",
    "#         address_locality = listing.select_one(\".locality\")\n",
    "#         full_address = \" \".join(filter(None, [\n",
    "#             address_street.text.strip() if address_street else \"\",\n",
    "#             address_locality.text.strip() if address_locality else \"\"\n",
    "#         ]))\n",
    "#         website = listing.select_one(\".track-visit-website\")[\"href\"] if listing.select_one(\".track-visit-website\") else \"N/A\"\n",
    "#         detail_link = \"https://www.yellowpages.com\" + listing.select_one(\".business-name\")[\"href\"]\n",
    "\n",
    "#         return {\n",
    "#             \"Company Name\": company,\n",
    "#             \"Industry\": \"Construction\",\n",
    "#             \"Contact Name\": \"\",\n",
    "#             \"Email Address\": \"\",\n",
    "#             \"Phone Number\": phone,\n",
    "#             \"Website URL\": website,\n",
    "#             \"Address\": full_address,\n",
    "#             \"Date Added\": datetime.now().strftime(\"%-m/%-d/%y\"),\n",
    "#             \"Date Contacted\": \"\",\n",
    "#             \"Contacted\": \"\",\n",
    "#             \"Notes\": detail_link,\n",
    "#             \"My Offering\": \"$1,500 setup $20 per month (blog, landing & contact form)\",\n",
    "#             \"Page\": page_number if page_number else 1\n",
    "#         }\n",
    "#     except Exception as e:\n",
    "#         print(\"Skipping listing due to parse error:\", e)\n",
    "#         return None\n",
    "\n",
    "# def scrape_yellowpages_rendered(base_url, max_pages):\n",
    "#     options = uc.ChromeOptions()\n",
    "#     if HEADLESS:\n",
    "#         options.add_argument(\"--headless=new\")\n",
    "#     options.add_argument(\"--no-sandbox\")\n",
    "#     options.add_argument(\"--disable-dev-shm-usage\")\n",
    "#     options.add_argument(f\"user-agent={USER_AGENT}\")\n",
    "\n",
    "#     driver = uc.Chrome(options=options)\n",
    "#     all_data = []\n",
    "\n",
    "#     for page in range(1, max_pages + 1):\n",
    "#         page_url = base_url if page == 1 else f\"{base_url}?page={page}\"\n",
    "#         print(f\"\\n➡️ Scraping Page {page}: {page_url}\")\n",
    "#         driver.get(page_url)\n",
    "\n",
    "#         try:\n",
    "#             WebDriverWait(driver, 15).until(\n",
    "#                 EC.presence_of_element_located((By.CLASS_NAME, \"result\"))\n",
    "#             )\n",
    "#         except:\n",
    "#             print(f\"⚠️ Timeout on page {page} — printing debug HTML:\")\n",
    "#             print(driver.page_source[:1000])\n",
    "#             continue\n",
    "\n",
    "#         driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "#         time.sleep(1.5)\n",
    "\n",
    "#         listings = driver.find_elements(By.CLASS_NAME, \"result\")\n",
    "#         print(f\"✔️ Found {len(listings)} listings on page {page}\")\n",
    "\n",
    "#         if not listings:\n",
    "#             break\n",
    "\n",
    "#         for listing in listings:\n",
    "#             soup = BeautifulSoup(listing.get_attribute(\"outerHTML\"), \"html.parser\")\n",
    "#             parsed = parse_listing(soup, page)\n",
    "#             if parsed:\n",
    "#                 all_data.append(parsed)\n",
    "\n",
    "#         # 👇 Randomized delay to reduce bot detection\n",
    "#         delay = random.uniform(4, 8)\n",
    "#         print(f\"⏳ Sleeping {delay:.2f}s before next page...\")\n",
    "#         time.sleep(delay)\n",
    "\n",
    "#     driver.quit()\n",
    "\n",
    "#     df = pd.DataFrame(all_data)\n",
    "#     if OUTPUT_FILE.endswith(\".csv\"):\n",
    "#         df.to_csv(OUTPUT_FILE, index=False)\n",
    "#     else:\n",
    "#         df.to_excel(OUTPUT_FILE, index=False)\n",
    "\n",
    "#     print(f\"\\n✅ Scraped {len(df)} total results. Saved to {OUTPUT_FILE}\")\n",
    "#     return df\n",
    "\n",
    "# # Run\n",
    "# if __name__ == \"__main__\":\n",
    "#     scrape_yellowpages_rendered(BASE_URL, MAX_PAGES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8178bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30 listings.\n",
      "Saved to yellow_pages_general_contractors.csv\n"
     ]
    }
   ],
   "source": [
    "# Manual Page number input\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "page_number = input(\"Enter page number: \")\n",
    "\n",
    "def parse_listing(listing):\n",
    "    try:\n",
    "        company = listing.select_one(\".business-name span\").text.strip()\n",
    "        phone = listing.select_one(\".phones\").text.strip() if listing.select_one(\".phones\") else \"\"\n",
    "        address_street = listing.select_one(\".street-address\")\n",
    "        address_locality = listing.select_one(\".locality\")\n",
    "        full_address = \" \".join(filter(None, [\n",
    "            address_street.text.strip() if address_street else \"\",\n",
    "            address_locality.text.strip() if address_locality else \"\"\n",
    "        ]))\n",
    "        website = listing.select_one(\".track-visit-website\")[\"href\"] if listing.select_one(\".track-visit-website\") else \"N/A\"\n",
    "        detail_link = \"https://www.yellowpages.com\" + listing.select_one(\".business-name\")[\"href\"]\n",
    "\n",
    "        return {\n",
    "            \"Company Name\": company,\n",
    "            \"Industry\": \"Construction\",\n",
    "            \"Contact Name\": \"\",\n",
    "            \"Email Address\": \"\",\n",
    "            \"Phone Number\": phone,\n",
    "            \"Website URL\": website,\n",
    "            \"Address\": full_address,\n",
    "            \"Date Added\": datetime.now().strftime(\"%-m/%-d/%y\"),\n",
    "            \"Date Contacted\": \"\",\n",
    "            \"Contacted\": \"\",\n",
    "            \"Notes\": detail_link,\n",
    "            \"My Offering\": \"$1,500 setup $20 per month (blog, landing & contact form)\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(\"Skipping listing due to parse error:\", e)\n",
    "        return None\n",
    "\n",
    "def scrape_yellowpages_rendered(url):\n",
    "    # Set up headless browser\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless\")  # Use classic headless mode\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n",
    "\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    driver.get(url)\n",
    "\n",
    "    # Scroll to trigger full JS content load\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(2)\n",
    "\n",
    "    try:\n",
    "        WebDriverWait(driver, 15).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"result\"))\n",
    "        )\n",
    "    except:\n",
    "        print(\"Timeout waiting for listings to load.\")\n",
    "        print(driver.page_source[:1000])  # Debug: see what’s loaded\n",
    "        driver.quit()\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "    listings = driver.find_elements(By.CLASS_NAME, \"result\")\n",
    "    print(f\"Found {len(listings)} listings.\")\n",
    "\n",
    "    data = []\n",
    "    for listing in listings:\n",
    "        soup = BeautifulSoup(listing.get_attribute(\"outerHTML\"), \"html.parser\")\n",
    "        parsed = parse_listing(soup)\n",
    "        if parsed:\n",
    "            data.append(parsed)\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    # Save to CSV\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(f\"yellow_pages_general_contractors_{page_number}.csv\", index=False)\n",
    "    print(f\"Saved to yellow_pages_general_contractors_{page_number}.csv\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 🔁 Run it\n",
    "if __name__ == \"__main__\":\n",
    "    url = f\"https://www.yellowpages.com/brooklyn-ny/general-contractors?page={page_number}\"\n",
    "    scrape_yellowpages_rendered(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2efeea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.worksheet.datavalidation import DataValidation\n",
    "\n",
    "def parse_listing(listing, source_url):\n",
    "    try:\n",
    "        company = listing.select_one(\".business-name span\").text.strip()\n",
    "        phone = listing.select_one(\".phones\").text.strip() if listing.select_one(\".phones\") else \"\"\n",
    "        address_street = listing.select_one(\".street-address\")\n",
    "        address_locality = listing.select_one(\".locality\")\n",
    "        full_address = \" \".join(filter(None, [\n",
    "            address_street.text.strip() if address_street else \"\",\n",
    "            address_locality.text.strip() if address_locality else \"\"\n",
    "        ]))\n",
    "        website = listing.select_one(\".track-visit-website\")[\"href\"] if listing.select_one(\".track-visit-website\") else \"N/A\"\n",
    "        detail_link = \"https://www.yellowpages.com\" + listing.select_one(\".business-name\")[\"href\"]\n",
    "\n",
    "        return {\n",
    "            \"Company Name\": company,\n",
    "            \"Industry\": \"Construction\",\n",
    "            \"Contact Name\": \"\",\n",
    "            \"Email Address\": \"\",\n",
    "            \"Phone Number\": phone,\n",
    "            \"Website URL\": website,\n",
    "            \"Address\": full_address,\n",
    "            \"Date Added\": datetime.now().strftime(\"%-m/%-d/%y\"),\n",
    "            \"Date Contacted\": \"\",\n",
    "            \"Notes\": detail_link,\n",
    "            \"Source\": source_url,\n",
    "            \"Called\": \"\",\n",
    "            \"Followed Up\": \"\",\n",
    "            \"Closed\": \"\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(\"Skipping listing due to parse error:\", e)\n",
    "        return None\n",
    "\n",
    "def add_checkboxes(filepath):\n",
    "    wb = load_workbook(filepath)\n",
    "    ws = wb.active\n",
    "    \n",
    "    checkbox_validation = DataValidation(type=\"list\", formula1='\"☐,☑\"', allow_blank=True)\n",
    "    ws.add_data_validation(checkbox_validation)\n",
    "    \n",
    "    # Find checkbox columns (Called, Followed Up, Closed)\n",
    "    headers = {cell.value: cell.column for cell in ws[1]}\n",
    "    checkbox_cols = [\"Called\", \"Followed Up\", \"Closed\"]\n",
    "    \n",
    "    for col_name in checkbox_cols:\n",
    "        if col_name in headers:\n",
    "            col_idx = headers[col_name]\n",
    "            col_letter = ws.cell(row=1, column=col_idx).column_letter\n",
    "            for row in range(2, ws.max_row + 1):\n",
    "                cell = ws.cell(row=row, column=col_idx)\n",
    "                cell.value = \"☐\"\n",
    "                checkbox_validation.add(cell)\n",
    "    \n",
    "    wb.save(filepath)\n",
    "\n",
    "def scrape_yellowpages_rendered(url):\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\"user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n",
    "\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "    driver.get(url)\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(2)\n",
    "\n",
    "    try:\n",
    "        WebDriverWait(driver, 15).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"result\"))\n",
    "        )\n",
    "    except:\n",
    "        print(\"Timeout waiting for listings to load.\")\n",
    "        print(driver.page_source[:1000])\n",
    "        driver.quit()\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    listings = driver.find_elements(By.CLASS_NAME, \"result\")\n",
    "    print(f\"Found {len(listings)} listings.\")\n",
    "\n",
    "    data = []\n",
    "    for listing in listings:\n",
    "        soup = BeautifulSoup(listing.get_attribute(\"outerHTML\"), \"html.parser\")\n",
    "        parsed = parse_listing(soup, url)\n",
    "        if parsed:\n",
    "            data.append(parsed)\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    output_file = \"yellow_pages_general_contractors.xlsx\"\n",
    "    df.to_excel(output_file, index=False)\n",
    "    \n",
    "    # Add checkbox validation\n",
    "    add_checkboxes(output_file)\n",
    "    \n",
    "    print(f\"Saved to {output_file}\")\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    url = \"https://www.yellowpages.com/brooklyn-ny/general-contractors\"\n",
    "    scrape_yellowpages_rendered(url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yp-scraper-env (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
